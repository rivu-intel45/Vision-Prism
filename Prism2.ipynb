{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf78b78b-dc71-49e5-a2bc-8a06ee649a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Samsung Prism\\visual assist\\vision\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\n",
      "0: 480x640 1 person, 134.0ms\n",
      "Speed: 2.8ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.8ms\n",
      "Speed: 2.4ms preprocess, 85.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.4ms\n",
      "Speed: 1.2ms preprocess, 69.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.8ms\n",
      "Speed: 1.2ms preprocess, 61.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.0ms\n",
      "Speed: 1.3ms preprocess, 75.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.7ms\n",
      "Speed: 2.6ms preprocess, 75.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.0ms\n",
      "Speed: 0.9ms preprocess, 54.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.5ms\n",
      "Speed: 2.1ms preprocess, 163.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.7ms\n",
      "Speed: 1.7ms preprocess, 93.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.7ms\n",
      "Speed: 1.9ms preprocess, 64.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.5ms\n",
      "Speed: 2.6ms preprocess, 69.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.5ms\n",
      "Speed: 1.1ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.7ms\n",
      "Speed: 1.2ms preprocess, 80.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.0ms\n",
      "Speed: 1.2ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.6ms\n",
      "Speed: 1.8ms preprocess, 70.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.8ms\n",
      "Speed: 1.5ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.2ms\n",
      "Speed: 2.0ms preprocess, 75.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.9ms\n",
      "Speed: 1.9ms preprocess, 80.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.5ms\n",
      "Speed: 1.9ms preprocess, 118.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.2ms\n",
      "Speed: 1.4ms preprocess, 106.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.6ms\n",
      "Speed: 1.5ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 62.1ms\n",
      "Speed: 1.5ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.2ms\n",
      "Speed: 1.9ms preprocess, 94.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.3ms\n",
      "Speed: 2.0ms preprocess, 61.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 57.5ms\n",
      "Speed: 1.7ms preprocess, 57.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.1ms\n",
      "Speed: 1.2ms preprocess, 56.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.2ms\n",
      "Speed: 2.0ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.6ms\n",
      "Speed: 1.4ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.7ms\n",
      "Speed: 3.4ms preprocess, 102.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.7ms\n",
      "Speed: 1.2ms preprocess, 67.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.2ms\n",
      "Speed: 1.3ms preprocess, 78.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.9ms\n",
      "Speed: 1.4ms preprocess, 60.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 57.0ms\n",
      "Speed: 1.1ms preprocess, 57.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.0ms\n",
      "Speed: 1.2ms preprocess, 61.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.2ms\n",
      "Speed: 1.0ms preprocess, 60.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.0ms\n",
      "Speed: 1.8ms preprocess, 74.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 63.8ms\n",
      "Speed: 1.8ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 63.2ms\n",
      "Speed: 1.6ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.1ms\n",
      "Speed: 1.7ms preprocess, 84.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.8ms\n",
      "Speed: 1.9ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.6ms\n",
      "Speed: 1.3ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 2.5ms preprocess, 83.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.2ms\n",
      "Speed: 1.0ms preprocess, 58.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.3ms\n",
      "Speed: 2.8ms preprocess, 93.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.3ms\n",
      "Speed: 1.3ms preprocess, 91.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.6ms\n",
      "Speed: 1.3ms preprocess, 139.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.5ms\n",
      "Speed: 8.1ms preprocess, 135.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.2ms\n",
      "Speed: 1.5ms preprocess, 131.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.6ms\n",
      "Speed: 9.9ms preprocess, 115.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.5ms\n",
      "Speed: 1.8ms preprocess, 71.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.0ms\n",
      "Speed: 1.0ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.3ms\n",
      "Speed: 1.4ms preprocess, 60.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.4ms\n",
      "Speed: 2.0ms preprocess, 94.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Samsung Prism\\visual assist\\vision\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QPushButton, QHBoxLayout\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer\n",
    "from ultralytics import YOLO\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class ObjectDetectionGUI(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = YOLO('yolov8n.pt')\n",
    "        pygame.mixer.init()\n",
    "        self.initUI()\n",
    "        self.detected_objects = []\n",
    "        self.conf_threshold = 0.5\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(30)\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Object Detection GUI')\n",
    "        self.setGeometry(100, 100, 960, 700)\n",
    "        self.video_label = QLabel(self)\n",
    "        self.video_label.setFixedSize(960, 540)\n",
    "\n",
    "        self.announce_btn = QPushButton('Announce')\n",
    "        self.announce_btn.clicked.connect(self.announce_objects)\n",
    "        self.conf_up_btn = QPushButton('Increase Confidence')\n",
    "        self.conf_up_btn.clicked.connect(self.conf_up)\n",
    "        self.conf_down_btn = QPushButton('Decrease Confidence')\n",
    "        self.conf_down_btn.clicked.connect(self.conf_down)\n",
    "        self.quit_btn = QPushButton('Quit')\n",
    "        self.quit_btn.clicked.connect(self.close_app)\n",
    "\n",
    "        hbox = QHBoxLayout()\n",
    "        hbox.addWidget(self.announce_btn)\n",
    "        hbox.addWidget(self.conf_up_btn)\n",
    "        hbox.addWidget(self.conf_down_btn)\n",
    "        hbox.addWidget(self.quit_btn)\n",
    "        \n",
    "        self.obj_label = QLabel(\"Detected objects will appear here.\")\n",
    "        self.obj_label.setWordWrap(True)\n",
    "\n",
    "        vbox = QVBoxLayout()\n",
    "        vbox.addWidget(self.video_label)\n",
    "        vbox.addLayout(hbox)\n",
    "        vbox.addWidget(self.obj_label)\n",
    "        self.setLayout(vbox)\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            objects_in_frame, boxed_frame = self.detect_objects(frame)\n",
    "            self.detected_objects = objects_in_frame\n",
    "\n",
    "            # Convert OpenCV frame to Qt format and display\n",
    "            rgb_image = cv2.cvtColor(boxed_frame, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            self.video_label.setPixmap(QPixmap.fromImage(qt_image))\n",
    "            \n",
    "            # Show objects in label\n",
    "            objects_str = \", \".join([f\"{obj[0]}({obj[1]:.2f})\" for obj in objects_in_frame])\n",
    "            self.obj_label.setText(f\"Detected: {objects_str}\\nConfidence threshold: {self.conf_threshold:.2f}\")\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        results = self.model(frame, conf=self.conf_threshold)\n",
    "        objects = []\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    label = self.model.names[int(box.cls[0])]\n",
    "                    conf = float(box.conf[0])\n",
    "                    color = (0,255,0) if conf > 0.7 else (0,255,255) if conf > 0.5 else (0,165,255)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1-5), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    objects.append((label, conf))\n",
    "        return objects, frame\n",
    "\n",
    "    def text_to_speech(self, text):\n",
    "        filename = f\"speech_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3\"\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save(filename)\n",
    "        pygame.mixer.music.load(filename)\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.Clock().tick(20)\n",
    "        pygame.mixer.music.unload()\n",
    "        os.remove(filename)\n",
    "\n",
    "    def announce_objects(self):\n",
    "        if not self.detected_objects:\n",
    "            self.text_to_speech(\"No objects detected.\")\n",
    "            return\n",
    "        summary = \"The follwing objects can be detected\" + \", \".join(f\"a {obj[0]}\" for obj in self.detected_objects if obj[1] > self.conf_threshold)\n",
    "        self.text_to_speech(summary)\n",
    "\n",
    "    def conf_up(self):\n",
    "        self.conf_threshold = min(0.95, self.conf_threshold + 0.05)\n",
    "\n",
    "    def conf_down(self):\n",
    "        self.conf_threshold = max(0.05, self.conf_threshold - 0.05)\n",
    "\n",
    "    def close_app(self):\n",
    "        self.cap.release()\n",
    "        pygame.mixer.quit()\n",
    "        self.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    od_app = ObjectDetectionGUI()\n",
    "    od_app.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5e2d8-42b3-4b75-977e-ada5d251bcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vision)",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
